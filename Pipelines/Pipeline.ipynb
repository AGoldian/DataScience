{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Pipelines**","metadata":{}},{"cell_type":"markdown","source":"## 1. Создание Pipeline с использованием стандартных функций ","metadata":{}},{"cell_type":"markdown","source":"#### Демонстрацию работы с конвеерами данных Pipeline будем демонстрировать на классификации набора данных \"fetch_20newsgroups\", содержащий новостные документы, разделённые по группам.  https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html","metadata":{}},{"cell_type":"code","source":"#подключаем необходимые библиотеки\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import Normalizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"id":"00onhNVfU1OJ","execution":{"iopub.status.busy":"2022-05-31T16:14:42.462280Z","iopub.execute_input":"2022-05-31T16:14:42.462622Z","iopub.status.idle":"2022-05-31T16:14:43.603973Z","shell.execute_reply.started":"2022-05-31T16:14:42.462541Z","shell.execute_reply":"2022-05-31T16:14:43.603238Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#### Выгружаем данные, при этом перемешивая и удаляя разметочную информацию","metadata":{}},{"cell_type":"code","source":"data_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=228, remove=('headers', 'footers', 'quotes'))\ndata_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=228, remove=('headers', 'footers', 'quotes'))","metadata":{"id":"CJLnFe2VViKr","execution":{"iopub.status.busy":"2022-05-31T14:56:28.499799Z","iopub.execute_input":"2022-05-31T14:56:28.500186Z","iopub.status.idle":"2022-05-31T14:56:31.727083Z","shell.execute_reply.started":"2022-05-31T14:56:28.500152Z","shell.execute_reply":"2022-05-31T14:56:31.726201Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data_train.target_names","metadata":{"id":"6yry_-6vVqlS","outputId":"cd552ac8-c7d3-47c4-b3cd-73552bddd0be","execution":{"iopub.status.busy":"2022-05-31T14:56:31.729696Z","iopub.execute_input":"2022-05-31T14:56:31.730233Z","iopub.status.idle":"2022-05-31T14:56:31.736793Z","shell.execute_reply.started":"2022-05-31T14:56:31.730195Z","shell.execute_reply":"2022-05-31T14:56:31.735673Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Определяем первый наш конвеер, с использованием векторизатора\npreprocessor = Pipeline(steps=[('embeddings', TfidfVectorizer())])","metadata":{"id":"CaJiXKp-VsRN","execution":{"iopub.status.busy":"2022-05-31T14:56:31.738600Z","iopub.execute_input":"2022-05-31T14:56:31.739055Z","iopub.status.idle":"2022-05-31T14:56:31.745655Z","shell.execute_reply.started":"2022-05-31T14:56:31.739017Z","shell.execute_reply":"2022-05-31T14:56:31.744760Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"#### Обучаем логистическую регрессию с использованием простого Pipeline","metadata":{}},{"cell_type":"code","source":"pipeline = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\npipeline.fit(data_train.data, data_train.target)\npipeline.score(data_test.data, data_test.target)","metadata":{"id":"tUyTOJZGVwwH","outputId":"907c396c-0a2c-4624-fbff-ad130232aa71","execution":{"iopub.status.busy":"2022-05-31T14:56:31.747691Z","iopub.execute_input":"2022-05-31T14:56:31.748086Z","iopub.status.idle":"2022-05-31T14:57:21.894031Z","shell.execute_reply.started":"2022-05-31T14:56:31.748033Z","shell.execute_reply":"2022-05-31T14:57:21.893284Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### Результат классификации - **0.67**, запомним его для финального сравнения с более сложными конвеерами","metadata":{}},{"cell_type":"markdown","source":"## 2. Применение функции make_pipeline с нормализатором данных","metadata":{}},{"cell_type":"markdown","source":"#### Примененим к данным функции нормализации, а также уменьшение размерности, для того чтобы ускорить процесс обучения логистической регрессии.","metadata":{}},{"cell_type":"code","source":"data_train = fetch_20newsgroups(subset='train', \n                                shuffle=True, random_state=228,\n                                remove=('headers', 'footers', 'quotes'))\nn_components = 2\nvectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english', use_idf=True)\nX_train = vectorizer.fit_transform(data_train.data)\n\nsvd = TruncatedSVD(n_components)\nnormalizer = Normalizer(copy=False)\nlsa = make_pipeline(svd, normalizer)\nX_train = lsa.fit_transform(X_train)","metadata":{"id":"Dj_-zKSuV4Lt","execution":{"iopub.status.busy":"2022-05-31T15:51:24.921968Z","iopub.execute_input":"2022-05-31T15:51:24.922915Z","iopub.status.idle":"2022-05-31T15:51:28.749815Z","shell.execute_reply.started":"2022-05-31T15:51:24.922867Z","shell.execute_reply":"2022-05-31T15:51:28.749035Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"data_test = fetch_20newsgroups(subset='test', \n                               shuffle=True, random_state=228,\n                               remove=('headers', 'footers', 'quotes'))\n\ntarget_names = data_train.target_names\n\ny_train, y_test = data_train.target, data_test.target\nX_test = vectorizer.transform(data_test.data)\nX_test = lsa.fit_transform(X_test)","metadata":{"id":"Cq3Sq960W6zr","execution":{"iopub.status.busy":"2022-05-31T15:52:28.922813Z","iopub.execute_input":"2022-05-31T15:52:28.923189Z","iopub.status.idle":"2022-05-31T15:52:31.254948Z","shell.execute_reply.started":"2022-05-31T15:52:28.923158Z","shell.execute_reply":"2022-05-31T15:52:31.254090Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"# Обучим также логистическую регрессию\nlr_clf = LogisticRegression(max_iter=10000)\nlr_clf.fit(X_train, y_train)","metadata":{"id":"h9TSSt3-XAOs","outputId":"5f421f52-5d24-43a7-9061-0d5401555fbb","execution":{"iopub.status.busy":"2022-05-31T15:52:31.256553Z","iopub.execute_input":"2022-05-31T15:52:31.257007Z","iopub.status.idle":"2022-05-31T15:52:54.085895Z","shell.execute_reply.started":"2022-05-31T15:52:31.256972Z","shell.execute_reply":"2022-05-31T15:52:54.084883Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"lr_pred = lr_clf.predict(X_train)\ntrain_score = accuracy_score(y_train, lr_pred) * 100\nprint(f\"Оценка по тренировочным данным: {train_score:.2f}%\")\n\nlr_pred = lr_clf.predict(X_test)\ntest_score = accuracy_score(y_test, lr_pred) * 100\nprint(f\"Оценка по тестовым данным: {test_score:.2f}%\")","metadata":{"id":"OZz5QA6qXBdm","outputId":"49c36152-6f39-4d93-cc9d-3db14fa6ac73","execution":{"iopub.status.busy":"2022-05-31T15:52:54.087836Z","iopub.execute_input":"2022-05-31T15:52:54.088430Z","iopub.status.idle":"2022-05-31T15:52:54.120568Z","shell.execute_reply.started":"2022-05-31T15:52:54.088349Z","shell.execute_reply":"2022-05-31T15:52:54.119608Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"#### Как можно заметить результат стал хуже, потому что на него сильно влияет размерность выборки, посмотрим на результат без его применения","metadata":{}},{"cell_type":"code","source":"X_train = vectorizer.fit_transform(data_train.data)\nlsa = make_pipeline(normalizer)\nX_train = lsa.fit_transform(X_train)\nX_test = vectorizer.transform(data_test.data)\nX_test = lsa.fit_transform(X_test)\n\nlr_clf = LogisticRegression(max_iter=10000)\nlr_clf.fit(X_train, y_train)\nlr_pred = lr_clf.predict(X_train)\n\ntrain_score = accuracy_score(y_train, lr_pred) * 100\nprint(f\"Оценка по тренировочным данным: {train_score:.2f}%\")\n\nlr_pred = lr_clf.predict(X_test)\ntest_score = accuracy_score(y_test, lr_pred) * 100\nprint(f\"Оценка по тестовым данным: {test_score:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:01:25.933456Z","iopub.execute_input":"2022-05-31T16:01:25.933811Z","iopub.status.idle":"2022-05-31T16:01:52.151360Z","shell.execute_reply.started":"2022-05-31T16:01:25.933782Z","shell.execute_reply":"2022-05-31T16:01:52.150536Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":"#### Точность значительно выросла, и немного выросла по сравнению с первой классификацией.","metadata":{}},{"cell_type":"markdown","source":"#### Рассмотрим точность по всем группам","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(classification_report(y_test, lr_pred, output_dict=True)).T","metadata":{"id":"CooCUFuhXCkX","outputId":"191d3e64-3e69-48c7-a71c-8c1fbbb67774","execution":{"iopub.status.busy":"2022-05-31T16:04:34.763740Z","iopub.execute_input":"2022-05-31T16:04:34.764112Z","iopub.status.idle":"2022-05-31T16:04:34.801465Z","shell.execute_reply.started":"2022-05-31T16:04:34.764080Z","shell.execute_reply":"2022-05-31T16:04:34.800679Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":"#### Построим матрицу корреляции для визуализации полученных данных","metadata":{}},{"cell_type":"code","source":"import matplotlib as plt\n\ncm = confusion_matrix(y_test, lr_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=data_train.target_names)\n\n\nfig, ax = plt.subplots(figsize=(10, 10))\ndisp = disp.plot(xticks_rotation='vertical', ax=ax, cmap='summer')\n\nplt.show()","metadata":{"id":"IKAr6-fpXDge","outputId":"9c17ca90-7c8c-4a81-fee0-4a35ba930695","execution":{"iopub.status.busy":"2022-05-31T16:05:55.776737Z","iopub.execute_input":"2022-05-31T16:05:55.777317Z","iopub.status.idle":"2022-05-31T16:05:57.129870Z","shell.execute_reply.started":"2022-05-31T16:05:55.777276Z","shell.execute_reply":"2022-05-31T16:05:57.128910Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"markdown","source":"## 3. Продвинутые контейнеры данных с применением NLTK","metadata":{}},{"cell_type":"code","source":"newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\nnewsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n\nX_train = np.array(newsgroups_train.data)\ny_train = np.array(newsgroups_train.target)\nX_test = np.array(newsgroups_test.data)\ny_test = np.array(newsgroups_test.target)","metadata":{"id":"Yapgkq4jXZ3m","execution":{"iopub.status.busy":"2022-05-31T16:14:56.707881Z","iopub.execute_input":"2022-05-31T16:14:56.708158Z","iopub.status.idle":"2022-05-31T16:15:17.439181Z","shell.execute_reply.started":"2022-05-31T16:14:56.708122Z","shell.execute_reply":"2022-05-31T16:15:17.438590Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"#### Рассмотрим разделение количество новостных документов по всем анализируемым группам","metadata":{}},{"cell_type":"code","source":"def conta_labels(y_train, y_test):\n    y_train_classes = pd.DataFrame([newsgroups_train.target_names[i] for i in newsgroups_train.target])[0]\n    y_test_classes = pd.DataFrame([newsgroups_test.target_names[i] for i in newsgroups_test.target])[0]\n    \n    contagem_df = pd.concat([y_train_classes.value_counts(),\n                             y_test_classes.value_counts()],\n                            axis=1, \n                            keys=[\"Тренировочные\", \"Тестовые\"], \n                            sort=False)\n    \n    contagem_df[\"Общие\"] = contagem_df.sum(axis=1)\n    contagem_df.loc[\"Сумма\"] = contagem_df.sum(axis=0)\n    \n    return contagem_df\n\nnewsgroups_df_labels = conta_labels(y_train, y_test)\nnewsgroups_df_labels","metadata":{"id":"gDywPnA5Xn_K","outputId":"277a2540-e95d-4967-f784-5765ac816f4d","execution":{"iopub.status.busy":"2022-05-31T16:15:17.440458Z","iopub.execute_input":"2022-05-31T16:15:17.440769Z","iopub.status.idle":"2022-05-31T16:15:17.502869Z","shell.execute_reply.started":"2022-05-31T16:15:17.440744Z","shell.execute_reply":"2022-05-31T16:15:17.502227Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"newsgroups_df_labels.iloc[:-1,:-1].plot.barh(stacked=True, \n                                    figsize=(10, 8),\n                                    color = 'cym',\n                                    title=\"Количество документов на каждый класс\");","metadata":{"id":"KllVAkWedeZZ","outputId":"3e260b4a-d1a0-4d04-8b00-dc82d67fb31d","execution":{"iopub.status.busy":"2022-05-31T16:15:17.504093Z","iopub.execute_input":"2022-05-31T16:15:17.504342Z","iopub.status.idle":"2022-05-31T16:15:17.961867Z","shell.execute_reply.started":"2022-05-31T16:15:17.504306Z","shell.execute_reply":"2022-05-31T16:15:17.959710Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Используем модуль для обработки языка - NLTK. И создадим класс, который получает на вход новостной документ, а возравращает наборы слов с удалёнными стоп-словами и пунктуационными знаками.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn import metrics","metadata":{"id":"IIOtPmP6di-4","execution":{"iopub.status.busy":"2022-05-31T16:15:17.963544Z","iopub.execute_input":"2022-05-31T16:15:17.963904Z","iopub.status.idle":"2022-05-31T16:15:17.967188Z","shell.execute_reply.started":"2022-05-31T16:15:17.963875Z","shell.execute_reply":"2022-05-31T16:15:17.966475Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import string\nimport re\nimport nltk\n\nclass NLTKTokenizer(): \n    def __init__(self):\n        self.lemmatizer = nltk.stem.WordNetLemmatizer()\n        self.stopwords = nltk.corpus.stopwords.words('english')\n        self.english_words = set(nltk.corpus.words.words())\n        self.pontuacao = string.punctuation\n\n    def __call__(self, doc):\n        doc = doc.lower()       \n        doc = re.sub(r'[0-9]+', 'num', doc)\n        doc = re.sub(r'[_]+', 'underline', doc)\n        doc = re.sub(r'(http|https)://[^\\s]*', 'http', doc)\n        doc = re.sub(r'[^\\s]+@[^\\s]+', 'email', doc) \n        doc = re.sub(r'\\\\r\\\\n', ' ', doc)\n        doc = re.sub(r'\\W', ' ', doc)\n        doc = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', doc)\n        doc = re.sub(r'\\^[a-zA-Z]\\s+', ' ', doc) \n        doc = re.sub(r'\\s+', ' ', doc, flags=re.I)\n        palavras = []\n        for word in nltk.word_tokenize(doc):\n            if word in self.stopwords:\n                continue\n            if word in self.pontuacao:\n                continue\n            if word not in self.english_words:\n                continue\n            \n            word = self.lemmatizer.lemmatize(word)\n            palavras.append(word)\n        \n        return palavras","metadata":{"id":"r7u5POkFdkNd","outputId":"6b427d91-cd17-41ad-dcfa-b55170244c6c","execution":{"iopub.status.busy":"2022-05-31T16:15:17.968592Z","iopub.execute_input":"2022-05-31T16:15:17.968947Z","iopub.status.idle":"2022-05-31T16:15:18.356701Z","shell.execute_reply.started":"2022-05-31T16:15:17.968918Z","shell.execute_reply":"2022-05-31T16:15:18.355870Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### Преобразуем данные в векторные признаки с помощью библиотек NLTK и регулярных выражений.\n","metadata":{}},{"cell_type":"code","source":"vectorizator = CountVectorizer()\nv1 = vectorizator.fit_transform(X_train)\n\nfeatures = vectorizator.get_feature_names()\nv1_df = pd.DataFrame(v1.toarray(), columns = features)\nv1_df","metadata":{"id":"_ZRuLyybdnAf","outputId":"13a6daba-7f60-4528-e9b0-0f696ca8071c","execution":{"iopub.status.busy":"2022-05-31T16:16:45.322963Z","iopub.execute_input":"2022-05-31T16:16:45.323246Z","iopub.status.idle":"2022-05-31T16:16:52.791217Z","shell.execute_reply.started":"2022-05-31T16:16:45.323219Z","shell.execute_reply":"2022-05-31T16:16:52.790442Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Добавляем название признакам и используем наш токенизатор. (Лемматизация, удаление стоп-слов и неизвестных слов)","metadata":{}},{"cell_type":"code","source":"nltk_vectorizator = CountVectorizer(tokenizer=NLTKTokenizer())\nv2 = nltk_vectorizator.fit_transform(X_train)\n\nfeatures = nltk_vectorizator.get_feature_names()\nv2_df = pd.DataFrame(v2.toarray(), columns = features)\nv2_df","metadata":{"id":"BYnxifsodoTa","execution":{"iopub.status.busy":"2022-05-31T16:16:52.792464Z","iopub.execute_input":"2022-05-31T16:16:52.792672Z","iopub.status.idle":"2022-05-31T16:17:36.071338Z","shell.execute_reply.started":"2022-05-31T16:16:52.792648Z","shell.execute_reply":"2022-05-31T16:17:36.070513Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#### Логистическая регрессия: с применением конвейера данных (TfidfVectorizer, TfidfTransformer, LogisticRegression)","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n\ntext_clf_logistic_regression = Pipeline([('vect', TfidfVectorizer(max_df=0.5, min_df=2, \n                                                              stop_words='english', \n                                                              use_idf=True)),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', LogisticRegression(penalty='l2', \n                                                dual=False, \n                                                tol=0.001, \n                                                C=1.0, \n                                                fit_intercept=True, \n                                                intercept_scaling=1, \n                                                class_weight=None, \n                                                random_state=None, \n                                                solver='lbfgs', \n                                                max_iter=1000, \n                                                multi_class='multinomial', \n                                                verbose=0, \n                                                warm_start=False, \n                                                n_jobs=None, \n                                                l1_ratio=None)),\n                     ])\n\ntext_clf_logistic_regression.fit(X_train, y_train)\npredicted = text_clf_logistic_regression.predict(X_test)\nlr_tf_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"AuihcFZkgEiu","execution":{"iopub.status.busy":"2022-05-31T15:30:28.945492Z","iopub.execute_input":"2022-05-31T15:30:28.945845Z","iopub.status.idle":"2022-05-31T15:30:58.181228Z","shell.execute_reply.started":"2022-05-31T15:30:28.945813Z","shell.execute_reply":"2022-05-31T15:30:58.180350Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"#### Логистическая регрессия: с применением конвейера данных (NLTKTokenizer, TfidfTransformer, LogisticRegression)","metadata":{}},{"cell_type":"code","source":"text_clf_logistic_regression = Pipeline([('vect', CountVectorizer(tokenizer=NLTKTokenizer())),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', LogisticRegression(penalty='l2', \n                                                dual=False, \n                                                tol=0.001, \n                                                C=1.0, \n                                                fit_intercept=True, \n                                                intercept_scaling=1, \n                                                class_weight=None, \n                                                random_state=None, \n                                                solver='lbfgs', \n                                                max_iter=1000, \n                                                multi_class='multinomial', \n                                                verbose=0, \n                                                warm_start=False, \n                                                n_jobs=None, \n                                                l1_ratio=None)),\n                     ])\n\ntext_clf_logistic_regression.fit(X_train, y_train)\npredicted = text_clf_logistic_regression.predict(X_test)\nlr_nltk_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"CIwTdn1UgG9A","execution":{"iopub.status.busy":"2022-05-31T15:01:34.977002Z","iopub.execute_input":"2022-05-31T15:01:34.977887Z","iopub.status.idle":"2022-05-31T15:02:46.403714Z","shell.execute_reply.started":"2022-05-31T15:01:34.977845Z","shell.execute_reply":"2022-05-31T15:02:46.402559Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"#### Классификация ближайших соседей","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\ntext_clf_knn = Pipeline([('vect', TfidfVectorizer(max_df=0.5, min_df=2, \n                                                              stop_words='english', \n                                                              use_idf=True)),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', KNeighborsClassifier(n_neighbors=5, \n                                                  weights='uniform', \n                                                  algorithm='auto', \n                                                  leaf_size=30, \n                                                  p=2, \n                                                  metric='minkowski', \n                                                  metric_params=None, \n                                                  n_jobs=None)),\n                     ])\n\ntext_clf_knn.fit(X_train, y_train)\npredicted = text_clf_knn.predict(X_test)\nknn_tf_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"cRNvsF5OjHn8","execution":{"iopub.status.busy":"2022-05-31T15:02:46.406955Z","iopub.execute_input":"2022-05-31T15:02:46.407494Z","iopub.status.idle":"2022-05-31T15:02:58.800359Z","shell.execute_reply.started":"2022-05-31T15:02:46.407445Z","shell.execute_reply":"2022-05-31T15:02:58.798443Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"text_clf_knn = Pipeline([('vect', CountVectorizer(tokenizer=NLTKTokenizer())),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', KNeighborsClassifier(n_neighbors=5, \n                                                  weights='uniform', \n                                                  algorithm='auto', \n                                                  leaf_size=30, \n                                                  p=2, \n                                                  metric='minkowski', \n                                                  metric_params=None, \n                                                  n_jobs=None)),\n                     ])\n\ntext_clf_knn.fit(X_train, y_train)\npredicted = text_clf_knn.predict(X_test)\nknn_nltk_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"DyxVcDM-jIIL","execution":{"iopub.status.busy":"2022-05-31T15:02:58.802273Z","iopub.execute_input":"2022-05-31T15:02:58.802910Z","iopub.status.idle":"2022-05-31T15:03:59.752964Z","shell.execute_reply.started":"2022-05-31T15:02:58.802868Z","shell.execute_reply":"2022-05-31T15:03:59.750992Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"#### Классификация случайного леса","metadata":{}},{"cell_type":"code","source":"text_clf_rf = Pipeline([('vect', TfidfVectorizer(max_df=0.5, min_df=2, \n                                                              stop_words='english', \n                                                              use_idf=True)),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', RandomForestClassifier(n_estimators=100, \n                                                    criterion='gini', \n                                                    max_depth=None, \n                                                    min_samples_split=2, \n                                                    min_samples_leaf=1, \n                                                    min_weight_fraction_leaf=0.0, \n                                                    max_features='auto', \n                                                    max_leaf_nodes=None, \n                                                    min_impurity_decrease=0.0, \n                                                    bootstrap=True, \n                                                    oob_score=False, \n                                                    n_jobs=None, \n                                                    random_state=None, \n                                                    verbose=0, \n                                                    warm_start=False))])\n\ntext_clf_rf.fit(X_train, y_train)\npredicted = text_clf_rf.predict(X_test)\nrfc_tf_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"V51epncxjKZ7","execution":{"iopub.status.busy":"2022-05-31T15:08:38.721413Z","iopub.execute_input":"2022-05-31T15:08:38.721762Z","iopub.status.idle":"2022-05-31T15:09:16.190181Z","shell.execute_reply.started":"2022-05-31T15:08:38.721732Z","shell.execute_reply":"2022-05-31T15:09:16.189286Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"text_clf_rf = Pipeline([('vect', TfidfVectorizer(max_df=0.5, min_df=2, \n                                                              stop_words='english', \n                                                              use_idf=True)),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', RandomForestClassifier(n_estimators=100, \n                                                    criterion='gini', \n                                                    max_depth=None, \n                                                    min_samples_split=2, \n                                                    min_samples_leaf=1, \n                                                    min_weight_fraction_leaf=0.0, \n                                                    max_features='auto', \n                                                    max_leaf_nodes=None, \n                                                    min_impurity_decrease=0.0, \n                                                    bootstrap=True, \n                                                    oob_score=False, \n                                                    n_jobs=None, \n                                                    random_state=None, \n                                                    verbose=0, \n                                                    warm_start=False))])\n\ntext_clf_rf.fit(X_train, y_train)\npredicted = text_clf_rf.predict(X_test)\nrfc_nltk_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"wJWsBo6ljLor","execution":{"iopub.status.busy":"2022-05-31T15:09:16.191629Z","iopub.execute_input":"2022-05-31T15:09:16.192261Z","iopub.status.idle":"2022-05-31T15:09:53.013602Z","shell.execute_reply.started":"2022-05-31T15:09:16.192222Z","shell.execute_reply":"2022-05-31T15:09:53.011969Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"#### Анализ полученных результатов","metadata":{}},{"cell_type":"code","source":"models = [('LogisticRegression_TV', lr_tf_score),\n          ('LogisticRegression_NLTK', lr_nltk_score),\n          ('KNeighborsClassifier_TV', knn_tf_score),\n          ('KNeighborsClassifier_NLTK', knn_nltk_score),\n          ('RandomForestClassifier_TV', rfc_tf_score),\n          ('RandomForestClassifier_NLTK', rfc_nltk_score)\n          ]","metadata":{"id":"RpfWcJEdjt_p","execution":{"iopub.status.busy":"2022-05-31T15:09:53.015319Z","iopub.execute_input":"2022-05-31T15:09:53.015854Z","iopub.status.idle":"2022-05-31T15:09:53.020538Z","shell.execute_reply.started":"2022-05-31T15:09:53.015814Z","shell.execute_reply":"2022-05-31T15:09:53.019783Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"total = pd.DataFrame(data=models, columns=['Model', 'Score'])\ntotal = total.sort_values(by=['Score'], ignore_index=True, ascending=False)\ntotal","metadata":{"id":"tOeIREdBjNVn","execution":{"iopub.status.busy":"2022-05-31T15:25:35.278151Z","iopub.execute_input":"2022-05-31T15:25:35.278793Z","iopub.status.idle":"2022-05-31T15:25:35.290425Z","shell.execute_reply.started":"2022-05-31T15:25:35.278757Z","shell.execute_reply":"2022-05-31T15:25:35.288941Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"#### Наилучший классификатор оказался - Логистическая регрессия, где мы снова смогли улучшить результат.","metadata":{}},{"cell_type":"markdown","source":"#### В каждом из классификаторов мы применяли 2 типа векторизаторов - собранный нами выше с примением модуля NLTK и TfidfTransformer, с немного изменными параметрами. Pipeline дают нам возможности удобно работать с данными и применять к ним одновременно несколько необходимых инструментов. Это позволяет нам последовательно обработать данные, без их утечки или потери.","metadata":{}},{"cell_type":"markdown","source":"#### Подводя итоги анализа данных с применением контейнера данных Pipeline:\n+ Наилучший результат показала модель Логистической регрессии с TF-IDF векторизатором.\n+ Векторизатор на основе предобработки данных NLTK показал результат хуже, только на одной модели он достиг лучшей точности - KNeighborsClassifier.\n+ Применение классификации ближайших соседий было бесполезно, что и стоило доказать, так как наши данные находятся в перемешанном варианте.\n","metadata":{}}]}
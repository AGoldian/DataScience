{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Pipelines**","metadata":{}},{"cell_type":"markdown","source":"## 1. Создание Pipeline с использованием стандартных функций ","metadata":{}},{"cell_type":"markdown","source":"#### Демонстрацию работы с конвеерами данных Pipeline будем демонстрировать на классификации набора данных \"fetch_20newsgroups\", содержащий новостные документы, разделённые по группам.  https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html","metadata":{}},{"cell_type":"code","source":"#подключаем необходимые библиотеки\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import Normalizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"id":"00onhNVfU1OJ","execution":{"iopub.status.busy":"2022-05-31T16:42:18.797863Z","iopub.execute_input":"2022-05-31T16:42:18.798542Z","iopub.status.idle":"2022-05-31T16:42:18.805169Z","shell.execute_reply.started":"2022-05-31T16:42:18.798506Z","shell.execute_reply":"2022-05-31T16:42:18.804239Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#### Выгружаем данные, при этом перемешивая и удаляя разметочную информацию","metadata":{}},{"cell_type":"code","source":"data_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=228, remove=('headers', 'footers', 'quotes'))\ndata_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=228, remove=('headers', 'footers', 'quotes'))","metadata":{"id":"CJLnFe2VViKr","execution":{"iopub.status.busy":"2022-05-31T16:42:19.214170Z","iopub.execute_input":"2022-05-31T16:42:19.214448Z","iopub.status.idle":"2022-05-31T16:42:22.810608Z","shell.execute_reply.started":"2022-05-31T16:42:19.214420Z","shell.execute_reply":"2022-05-31T16:42:22.809712Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_train.target_names","metadata":{"id":"6yry_-6vVqlS","outputId":"cd552ac8-c7d3-47c4-b3cd-73552bddd0be","execution":{"iopub.status.busy":"2022-05-31T16:42:22.812879Z","iopub.execute_input":"2022-05-31T16:42:22.813284Z","iopub.status.idle":"2022-05-31T16:42:22.819533Z","shell.execute_reply.started":"2022-05-31T16:42:22.813224Z","shell.execute_reply":"2022-05-31T16:42:22.818770Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Определяем первый наш конвеер, с использованием векторизатора\npreprocessor = Pipeline(steps=[('embeddings', TfidfVectorizer())])","metadata":{"id":"CaJiXKp-VsRN","execution":{"iopub.status.busy":"2022-05-31T16:42:22.820582Z","iopub.execute_input":"2022-05-31T16:42:22.820856Z","iopub.status.idle":"2022-05-31T16:42:22.829323Z","shell.execute_reply.started":"2022-05-31T16:42:22.820801Z","shell.execute_reply":"2022-05-31T16:42:22.828477Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"#### Обучаем логистическую регрессию с использованием простого Pipeline","metadata":{}},{"cell_type":"code","source":"pipeline = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\npipeline.fit(data_train.data, data_train.target)\npipeline.score(data_test.data, data_test.target)","metadata":{"id":"tUyTOJZGVwwH","outputId":"907c396c-0a2c-4624-fbff-ad130232aa71","execution":{"iopub.status.busy":"2022-05-31T16:42:22.831234Z","iopub.execute_input":"2022-05-31T16:42:22.831452Z","iopub.status.idle":"2022-05-31T16:43:16.690501Z","shell.execute_reply.started":"2022-05-31T16:42:22.831428Z","shell.execute_reply":"2022-05-31T16:43:16.689655Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#### Результат классификации - **0.67**, запомним его для финального сравнения с более сложными конвеерами","metadata":{}},{"cell_type":"markdown","source":"## 2. Применение функции make_pipeline с нормализатором данных","metadata":{}},{"cell_type":"markdown","source":"#### Примененим к данным функции нормализации, а также уменьшение размерности, для того чтобы ускорить процесс обучения логистической регрессии.","metadata":{}},{"cell_type":"code","source":"data_train = fetch_20newsgroups(subset='train', \n                                shuffle=True, random_state=228,\n                                remove=('headers', 'footers', 'quotes'))\nn_components = 2\nvectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english', use_idf=True)\nX_train = vectorizer.fit_transform(data_train.data)\n\nsvd = TruncatedSVD(n_components)\nnormalizer = Normalizer(copy=False)\nlsa = make_pipeline(svd, normalizer)\nX_train = lsa.fit_transform(X_train)","metadata":{"id":"Dj_-zKSuV4Lt","execution":{"iopub.status.busy":"2022-05-31T16:43:16.691880Z","iopub.execute_input":"2022-05-31T16:43:16.692669Z","iopub.status.idle":"2022-05-31T16:43:21.698522Z","shell.execute_reply.started":"2022-05-31T16:43:16.692617Z","shell.execute_reply":"2022-05-31T16:43:21.697571Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data_test = fetch_20newsgroups(subset='test', \n                               shuffle=True, random_state=228,\n                               remove=('headers', 'footers', 'quotes'))\n\ntarget_names = data_train.target_names\n\ny_train, y_test = data_train.target, data_test.target\nX_test = vectorizer.transform(data_test.data)\nX_test = lsa.fit_transform(X_test)","metadata":{"id":"Cq3Sq960W6zr","execution":{"iopub.status.busy":"2022-05-31T16:43:21.703746Z","iopub.execute_input":"2022-05-31T16:43:21.704547Z","iopub.status.idle":"2022-05-31T16:43:24.750951Z","shell.execute_reply.started":"2022-05-31T16:43:21.704494Z","shell.execute_reply":"2022-05-31T16:43:24.749957Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Обучим также логистическую регрессию\nlr_clf = LogisticRegression(max_iter=10000)\nlr_clf.fit(X_train, y_train)","metadata":{"id":"h9TSSt3-XAOs","outputId":"5f421f52-5d24-43a7-9061-0d5401555fbb","execution":{"iopub.status.busy":"2022-05-31T16:43:24.756139Z","iopub.execute_input":"2022-05-31T16:43:24.759255Z","iopub.status.idle":"2022-05-31T16:43:26.577314Z","shell.execute_reply.started":"2022-05-31T16:43:24.759195Z","shell.execute_reply":"2022-05-31T16:43:26.576348Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"lr_pred = lr_clf.predict(X_train)\ntrain_score = accuracy_score(y_train, lr_pred) * 100\nprint(f\"Оценка по тренировочным данным: {train_score:.2f}%\")\n\nlr_pred = lr_clf.predict(X_test)\ntest_score = accuracy_score(y_test, lr_pred) * 100\nprint(f\"Оценка по тестовым данным: {test_score:.2f}%\")","metadata":{"id":"OZz5QA6qXBdm","outputId":"49c36152-6f39-4d93-cc9d-3db14fa6ac73","execution":{"iopub.status.busy":"2022-05-31T16:43:26.582464Z","iopub.execute_input":"2022-05-31T16:43:26.583567Z","iopub.status.idle":"2022-05-31T16:43:26.606219Z","shell.execute_reply.started":"2022-05-31T16:43:26.583510Z","shell.execute_reply":"2022-05-31T16:43:26.605302Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"#### Как можно заметить результат стал хуже, потому что на него сильно влияет размерность выборки, посмотрим на результат без его применения","metadata":{}},{"cell_type":"code","source":"X_train = vectorizer.fit_transform(data_train.data)\nlsa = make_pipeline(normalizer)\nX_train = lsa.fit_transform(X_train)\nX_test = vectorizer.transform(data_test.data)\nX_test = lsa.fit_transform(X_test)\n\nlr_clf = LogisticRegression(max_iter=10000)\nlr_clf.fit(X_train, y_train)\nlr_pred = lr_clf.predict(X_train)\n\ntrain_score = accuracy_score(y_train, lr_pred) * 100\nprint(f\"Оценка по тренировочным данным: {train_score:.2f}%\")\n\nlr_pred = lr_clf.predict(X_test)\ntest_score = accuracy_score(y_test, lr_pred) * 100\nprint(f\"Оценка по тестовым данным: {test_score:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T16:43:26.611227Z","iopub.execute_input":"2022-05-31T16:43:26.611961Z","iopub.status.idle":"2022-05-31T16:43:52.560864Z","shell.execute_reply.started":"2022-05-31T16:43:26.611911Z","shell.execute_reply":"2022-05-31T16:43:52.560250Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### Точность значительно выросла, и немного выросла по сравнению с первой классификацией.","metadata":{}},{"cell_type":"markdown","source":"#### Рассмотрим точность по всем группам","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(classification_report(y_test, lr_pred, output_dict=True)).T","metadata":{"id":"CooCUFuhXCkX","outputId":"191d3e64-3e69-48c7-a71c-8c1fbbb67774","execution":{"iopub.status.busy":"2022-05-31T16:43:52.563242Z","iopub.execute_input":"2022-05-31T16:43:52.563580Z","iopub.status.idle":"2022-05-31T16:43:52.601335Z","shell.execute_reply.started":"2022-05-31T16:43:52.563548Z","shell.execute_reply":"2022-05-31T16:43:52.600762Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"#### Построим матрицу корреляции для визуализации полученных данных","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(y_test, lr_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=data_train.target_names)\n\n\nfig, ax = plt.subplots(figsize=(10, 10))\ndisp = disp.plot(xticks_rotation='vertical', ax=ax, cmap='summer')\n\nplt.show()","metadata":{"id":"IKAr6-fpXDge","outputId":"9c17ca90-7c8c-4a81-fee0-4a35ba930695","execution":{"iopub.status.busy":"2022-05-31T16:55:47.672668Z","iopub.execute_input":"2022-05-31T16:55:47.673854Z","iopub.status.idle":"2022-05-31T16:55:49.371914Z","shell.execute_reply.started":"2022-05-31T16:55:47.673775Z","shell.execute_reply":"2022-05-31T16:55:49.371025Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## 3. Продвинутые контейнеры данных с применением NLTK","metadata":{}},{"cell_type":"code","source":"newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\nnewsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n\nX_train = np.array(newsgroups_train.data)\ny_train = np.array(newsgroups_train.target)\nX_test = np.array(newsgroups_test.data)\ny_test = np.array(newsgroups_test.target)","metadata":{"id":"Yapgkq4jXZ3m","execution":{"iopub.status.busy":"2022-05-31T16:43:54.268551Z","iopub.execute_input":"2022-05-31T16:43:54.269369Z","iopub.status.idle":"2022-05-31T16:44:04.051182Z","shell.execute_reply.started":"2022-05-31T16:43:54.269328Z","shell.execute_reply":"2022-05-31T16:44:04.050585Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### Рассмотрим разделение количество новостных документов по всем анализируемым группам","metadata":{}},{"cell_type":"code","source":"def conta_labels(y_train, y_test):\n    y_train_classes = pd.DataFrame([newsgroups_train.target_names[i] for i in newsgroups_train.target])[0]\n    y_test_classes = pd.DataFrame([newsgroups_test.target_names[i] for i in newsgroups_test.target])[0]\n    \n    contagem_df = pd.concat([y_train_classes.value_counts(),\n                             y_test_classes.value_counts()],\n                            axis=1, \n                            keys=[\"Тренировочные\", \"Тестовые\"], \n                            sort=False)\n    \n    contagem_df[\"Общие\"] = contagem_df.sum(axis=1)\n    contagem_df.loc[\"Сумма\"] = contagem_df.sum(axis=0)\n    \n    return contagem_df\n\nnewsgroups_df_labels = conta_labels(y_train, y_test)\nnewsgroups_df_labels","metadata":{"id":"gDywPnA5Xn_K","outputId":"277a2540-e95d-4967-f784-5765ac816f4d","execution":{"iopub.status.busy":"2022-05-31T16:44:04.052596Z","iopub.execute_input":"2022-05-31T16:44:04.053023Z","iopub.status.idle":"2022-05-31T16:44:04.107829Z","shell.execute_reply.started":"2022-05-31T16:44:04.052994Z","shell.execute_reply":"2022-05-31T16:44:04.107288Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"newsgroups_df_labels.iloc[:-1,:-1].plot.barh(stacked=True, \n                                    figsize=(10, 8),\n                                    color = 'cym',\n                                    title=\"Количество документов на каждый класс\");","metadata":{"id":"KllVAkWedeZZ","outputId":"3e260b4a-d1a0-4d04-8b00-dc82d67fb31d","execution":{"iopub.status.busy":"2022-05-31T16:56:13.207369Z","iopub.execute_input":"2022-05-31T16:56:13.207782Z","iopub.status.idle":"2022-05-31T16:56:13.617452Z","shell.execute_reply.started":"2022-05-31T16:56:13.207745Z","shell.execute_reply":"2022-05-31T16:56:13.616650Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"#### Используем модуль для обработки языка - NLTK. И создадим класс, который получает на вход новостной документ, а возравращает наборы слов с удалёнными стоп-словами и пунктуационными знаками.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn import metrics","metadata":{"id":"IIOtPmP6di-4","execution":{"iopub.status.busy":"2022-05-31T16:44:04.588942Z","iopub.execute_input":"2022-05-31T16:44:04.589157Z","iopub.status.idle":"2022-05-31T16:44:04.593181Z","shell.execute_reply.started":"2022-05-31T16:44:04.589133Z","shell.execute_reply":"2022-05-31T16:44:04.592226Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import string\nimport re\nimport nltk\n\nclass NLTKTokenizer(): \n    def __init__(self):\n        self.lemmatizer = nltk.stem.WordNetLemmatizer()\n        self.stopwords = nltk.corpus.stopwords.words('english')\n        self.english_words = set(nltk.corpus.words.words())\n        self.pontuacao = string.punctuation\n\n    def __call__(self, doc):\n        doc = doc.lower()       \n        doc = re.sub(r'[0-9]+', 'num', doc)\n        doc = re.sub(r'[_]+', 'underline', doc)\n        doc = re.sub(r'(http|https)://[^\\s]*', 'http', doc)\n        doc = re.sub(r'[^\\s]+@[^\\s]+', 'email', doc) \n        doc = re.sub(r'\\\\r\\\\n', ' ', doc)\n        doc = re.sub(r'\\W', ' ', doc)\n        doc = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', doc)\n        doc = re.sub(r'\\^[a-zA-Z]\\s+', ' ', doc) \n        doc = re.sub(r'\\s+', ' ', doc, flags=re.I)\n        palavras = []\n        for word in nltk.word_tokenize(doc):\n            if word in self.stopwords:\n                continue\n            if word in self.pontuacao:\n                continue\n            if word not in self.english_words:\n                continue\n            \n            word = self.lemmatizer.lemmatize(word)\n            palavras.append(word)\n        \n        return palavras","metadata":{"id":"r7u5POkFdkNd","outputId":"6b427d91-cd17-41ad-dcfa-b55170244c6c","execution":{"iopub.status.busy":"2022-05-31T16:44:04.594285Z","iopub.execute_input":"2022-05-31T16:44:04.594519Z","iopub.status.idle":"2022-05-31T16:44:04.994564Z","shell.execute_reply.started":"2022-05-31T16:44:04.594492Z","shell.execute_reply":"2022-05-31T16:44:04.993686Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"#### Преобразуем данные в векторные признаки с помощью библиотек NLTK и регулярных выражений.\n","metadata":{}},{"cell_type":"code","source":"vectorizator = CountVectorizer()\nv1 = vectorizator.fit_transform(X_train)\n\nfeatures = vectorizator.get_feature_names()\nv1_df = pd.DataFrame(v1.toarray(), columns = features)\nv1_df","metadata":{"id":"_ZRuLyybdnAf","outputId":"13a6daba-7f60-4528-e9b0-0f696ca8071c","execution":{"iopub.status.busy":"2022-05-31T16:44:04.996861Z","iopub.execute_input":"2022-05-31T16:44:04.997307Z","iopub.status.idle":"2022-05-31T16:44:12.729039Z","shell.execute_reply.started":"2022-05-31T16:44:04.997266Z","shell.execute_reply":"2022-05-31T16:44:12.728301Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Добавляем название признакам и используем наш токенизатор. (Лемматизация, удаление стоп-слов и неизвестных слов)","metadata":{}},{"cell_type":"code","source":"nltk_vectorizator = CountVectorizer(tokenizer=NLTKTokenizer())\nv2 = nltk_vectorizator.fit_transform(X_train)\n\nfeatures = nltk_vectorizator.get_feature_names()\nv2_df = pd.DataFrame(v2.toarray(), columns = features)\nv2_df","metadata":{"id":"BYnxifsodoTa","execution":{"iopub.status.busy":"2022-05-31T16:44:12.730089Z","iopub.execute_input":"2022-05-31T16:44:12.730579Z","iopub.status.idle":"2022-05-31T16:44:55.268491Z","shell.execute_reply.started":"2022-05-31T16:44:12.730542Z","shell.execute_reply":"2022-05-31T16:44:55.267542Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"#### Логистическая регрессия: с применением конвейера данных (TfidfVectorizer, TfidfTransformer, LogisticRegression)","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n\ntext_clf_logistic_regression = Pipeline([('vect', TfidfVectorizer(max_df=0.5, min_df=2, \n                                                              stop_words='english', \n                                                              use_idf=True)),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', LogisticRegression(penalty='l2', \n                                                dual=False, \n                                                tol=0.001, \n                                                C=1.0, \n                                                fit_intercept=True, \n                                                intercept_scaling=1, \n                                                class_weight=None, \n                                                random_state=None, \n                                                solver='lbfgs', \n                                                max_iter=1000, \n                                                multi_class='multinomial', \n                                                verbose=0, \n                                                warm_start=False, \n                                                n_jobs=None, \n                                                l1_ratio=None)),\n                     ])\n\ntext_clf_logistic_regression.fit(X_train, y_train)\npredicted = text_clf_logistic_regression.predict(X_test)\nlr_tf_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"AuihcFZkgEiu","execution":{"iopub.status.busy":"2022-05-31T16:44:55.270092Z","iopub.execute_input":"2022-05-31T16:44:55.270920Z","iopub.status.idle":"2022-05-31T16:45:25.902961Z","shell.execute_reply.started":"2022-05-31T16:44:55.270874Z","shell.execute_reply":"2022-05-31T16:45:25.902129Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"#### Логистическая регрессия: с применением конвейера данных (NLTKTokenizer, TfidfTransformer, LogisticRegression)","metadata":{}},{"cell_type":"code","source":"text_clf_logistic_regression = Pipeline([('vect', CountVectorizer(tokenizer=NLTKTokenizer())),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', LogisticRegression(penalty='l2', \n                                                dual=False, \n                                                tol=0.001, \n                                                C=1.0, \n                                                fit_intercept=True, \n                                                intercept_scaling=1, \n                                                class_weight=None, \n                                                random_state=None, \n                                                solver='lbfgs', \n                                                max_iter=1000, \n                                                multi_class='multinomial', \n                                                verbose=0, \n                                                warm_start=False, \n                                                n_jobs=None, \n                                                l1_ratio=None)),\n                     ])\n\ntext_clf_logistic_regression.fit(X_train, y_train)\npredicted = text_clf_logistic_regression.predict(X_test)\nlr_nltk_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"CIwTdn1UgG9A","execution":{"iopub.status.busy":"2022-05-31T16:45:25.904013Z","iopub.execute_input":"2022-05-31T16:45:25.904222Z","iopub.status.idle":"2022-05-31T16:46:46.255472Z","shell.execute_reply.started":"2022-05-31T16:45:25.904198Z","shell.execute_reply":"2022-05-31T16:46:46.254603Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"#### Классификация ближайших соседей","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\ntext_clf_knn = Pipeline([('vect', TfidfVectorizer(max_df=0.5, min_df=2, \n                                                              stop_words='english', \n                                                              use_idf=True)),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', KNeighborsClassifier(n_neighbors=5, \n                                                  weights='uniform', \n                                                  algorithm='auto', \n                                                  leaf_size=30, \n                                                  p=2, \n                                                  metric='minkowski', \n                                                  metric_params=None, \n                                                  n_jobs=None)),\n                     ])\n\ntext_clf_knn.fit(X_train, y_train)\npredicted = text_clf_knn.predict(X_test)\nknn_tf_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"cRNvsF5OjHn8","execution":{"iopub.status.busy":"2022-05-31T16:46:46.256711Z","iopub.execute_input":"2022-05-31T16:46:46.256931Z","iopub.status.idle":"2022-05-31T16:47:01.756015Z","shell.execute_reply.started":"2022-05-31T16:46:46.256906Z","shell.execute_reply":"2022-05-31T16:47:01.755435Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"text_clf_knn = Pipeline([('vect', CountVectorizer(tokenizer=NLTKTokenizer())),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', KNeighborsClassifier(n_neighbors=5, \n                                                  weights='uniform', \n                                                  algorithm='auto', \n                                                  leaf_size=30, \n                                                  p=2, \n                                                  metric='minkowski', \n                                                  metric_params=None, \n                                                  n_jobs=None)),\n                     ])\n\ntext_clf_knn.fit(X_train, y_train)\npredicted = text_clf_knn.predict(X_test)\nknn_nltk_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"DyxVcDM-jIIL","execution":{"iopub.status.busy":"2022-05-31T16:47:01.757289Z","iopub.execute_input":"2022-05-31T16:47:01.757679Z","iopub.status.idle":"2022-05-31T16:48:13.711839Z","shell.execute_reply.started":"2022-05-31T16:47:01.757635Z","shell.execute_reply":"2022-05-31T16:48:13.711069Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"#### Классификация случайного леса","metadata":{}},{"cell_type":"code","source":"text_clf_rf = Pipeline([('vect', TfidfVectorizer(max_df=0.5, min_df=2, \n                                                              stop_words='english', \n                                                              use_idf=True)),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', RandomForestClassifier(n_estimators=100, \n                                                    criterion='gini', \n                                                    max_depth=None, \n                                                    min_samples_split=2, \n                                                    min_samples_leaf=1, \n                                                    min_weight_fraction_leaf=0.0, \n                                                    max_features='auto', \n                                                    max_leaf_nodes=None, \n                                                    min_impurity_decrease=0.0, \n                                                    bootstrap=True, \n                                                    oob_score=False, \n                                                    n_jobs=None, \n                                                    random_state=None, \n                                                    verbose=0, \n                                                    warm_start=False))])\n\ntext_clf_rf.fit(X_train, y_train)\npredicted = text_clf_rf.predict(X_test)\nrfc_tf_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"V51epncxjKZ7","execution":{"iopub.status.busy":"2022-05-31T16:48:13.713915Z","iopub.execute_input":"2022-05-31T16:48:13.714463Z","iopub.status.idle":"2022-05-31T16:49:03.235120Z","shell.execute_reply.started":"2022-05-31T16:48:13.714420Z","shell.execute_reply":"2022-05-31T16:49:03.234205Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"text_clf_rf = Pipeline([('vect', TfidfVectorizer(max_df=0.5, min_df=2, \n                                                              stop_words='english', \n                                                              use_idf=True)),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', RandomForestClassifier(n_estimators=100, \n                                                    criterion='gini', \n                                                    max_depth=None, \n                                                    min_samples_split=2, \n                                                    min_samples_leaf=1, \n                                                    min_weight_fraction_leaf=0.0, \n                                                    max_features='auto', \n                                                    max_leaf_nodes=None, \n                                                    min_impurity_decrease=0.0, \n                                                    bootstrap=True, \n                                                    oob_score=False, \n                                                    n_jobs=None, \n                                                    random_state=None, \n                                                    verbose=0, \n                                                    warm_start=False))])\n\ntext_clf_rf.fit(X_train, y_train)\npredicted = text_clf_rf.predict(X_test)\nrfc_nltk_score = accuracy_score(y_test, predicted)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"id":"wJWsBo6ljLor","execution":{"iopub.status.busy":"2022-05-31T16:49:03.236270Z","iopub.execute_input":"2022-05-31T16:49:03.236499Z","iopub.status.idle":"2022-05-31T16:49:52.830108Z","shell.execute_reply.started":"2022-05-31T16:49:03.236471Z","shell.execute_reply":"2022-05-31T16:49:52.829177Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"#### Анализ полученных результатов","metadata":{}},{"cell_type":"code","source":"models = [('LogisticRegression_TV', lr_tf_score),\n          ('LogisticRegression_NLTK', lr_nltk_score),\n          ('KNeighborsClassifier_TV', knn_tf_score),\n          ('KNeighborsClassifier_NLTK', knn_nltk_score),\n          ('RandomForestClassifier_TV', rfc_tf_score),\n          ('RandomForestClassifier_NLTK', rfc_nltk_score)\n          ]","metadata":{"id":"RpfWcJEdjt_p","execution":{"iopub.status.busy":"2022-05-31T16:49:52.831261Z","iopub.execute_input":"2022-05-31T16:49:52.831503Z","iopub.status.idle":"2022-05-31T16:49:52.836577Z","shell.execute_reply.started":"2022-05-31T16:49:52.831478Z","shell.execute_reply":"2022-05-31T16:49:52.835729Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"total = pd.DataFrame(data=models, columns=['Model', 'Score'])\ntotal = total.sort_values(by=['Score'], ignore_index=True, ascending=False)\ntotal","metadata":{"id":"tOeIREdBjNVn","execution":{"iopub.status.busy":"2022-05-31T16:49:52.838304Z","iopub.execute_input":"2022-05-31T16:49:52.838598Z","iopub.status.idle":"2022-05-31T16:49:52.859567Z","shell.execute_reply.started":"2022-05-31T16:49:52.838561Z","shell.execute_reply":"2022-05-31T16:49:52.858795Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"#### Наилучший классификатор оказался - Логистическая регрессия, где мы снова смогли улучшить результат.","metadata":{}},{"cell_type":"markdown","source":"#### В каждом из классификаторов мы применяли 2 типа векторизаторов - собранный нами выше с примением модуля NLTK и TfidfTransformer, с немного изменными параметрами. Pipeline дают нам возможности удобно работать с данными и применять к ним одновременно несколько необходимых инструментов. Это позволяет нам последовательно обработать данные, без их утечки или потери.","metadata":{}},{"cell_type":"markdown","source":"#### Подводя итоги анализа данных с применением контейнера данных Pipeline:\n+ Наилучший результат показала модель Логистической регрессии с TF-IDF векторизатором.\n+ Векторизатор на основе предобработки данных NLTK показал результат хуже, только на одной модели он достиг лучшей точности - KNeighborsClassifier.\n+ Применение классификации ближайших соседий было бесполезно, что и стоило доказать, так как наши данные находятся в перемешанном варианте.\n","metadata":{}}]}